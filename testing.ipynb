{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc2d5033-d97a-41d3-9dfa-3af95498e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63aebb0b",
   "metadata": {},
   "source": [
    "The following cell contains code for creating the author vector csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f6a81a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df = pd.read_csv(\"data/features/document_vectors.csv\")\n",
    "doc_values = doc_df.loc[:, ~doc_df.columns.isin(['doc_id', 'author_id'])]\n",
    "author_ids = set(doc_df[\"author_id\"])\n",
    "\n",
    "def make_author_vector(doc_vectors:np.ndarray) -> np.ndarray:\n",
    "    return np.mean(doc_vectors, axis=0)\n",
    "\n",
    "def make_author_vector_df(doc_df:pd.DataFrame, author_ids) -> pd.DataFrame:\n",
    "    \"\"\"Creates author vectors by averaging each author's documents into one\"\"\"\n",
    "    df_copy = doc_df.copy(deep=True).drop(columns=\"author_id\").drop(columns=\"doc_id\")\n",
    "    \n",
    "    author_ids_to_avs = {}\n",
    "    for author_id in author_ids:\n",
    "        doc_vectors = df_copy.loc[doc_df['author_id'] == author_id].values\n",
    "        author_ids_to_avs[author_id] = make_author_vector(doc_vectors)\n",
    "        \n",
    "    av_df = pd.DataFrame(author_ids_to_avs).T\n",
    "    av_df.columns = df_copy.columns\n",
    "\n",
    "    \n",
    "    return av_df\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef25d779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POS Unigram: NOUN                 2.474801\n",
       "POS Bigram: ('VERB', 'PRON')      2.518766\n",
       "POS Bigram: ('NOUN', 'ADP')       2.181848\n",
       "POS Bigram: ('VERB', 'DET')       2.051311\n",
       "POS Bigram: ('PROPN', 'PUNCT')    2.440638\n",
       "Function word: me                 3.239219\n",
       "Function word: yourself           4.178343\n",
       "Function word: these              3.296460\n",
       "Function word: doing              2.906452\n",
       "Function word: further            2.884852\n",
       "Function word: all                3.656222\n",
       "Function word: too                2.034635\n",
       "Function word: won                4.928485\n",
       "Letter: f                         2.091393\n",
       "Letter: G                         3.353575\n",
       "Letter: K                         3.649688\n",
       "Letter: R                         4.330837\n",
       "Emoji: ❤️                         2.443363\n",
       "Dependency label: dative          2.546225\n",
       "Mixed Bigram: ('.', 'INTJ')       2.345270\n",
       "Mixed Bigram: ('ADJ', 'to')       2.633592\n",
       "Mixed Bigram: ('VERB', 'you')     2.684187\n",
       "Morphology tag: Acc               2.701221\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "from components.processing import author_vectors, authors_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_author_identifying_features(author_id:str, threshold=2):\n",
    "    \"\"\"Direction of zscore is important for verbalizing, use absolute value to choose what to talk about\"\"\"\n",
    "    \n",
    "    zscores = abs(zscore(author_vectors))\n",
    "    idx = authors_df.loc[authors_df[\"author_id\"] == author_id].index[0]\n",
    "    author_zscores = zscores.iloc[idx]\n",
    "    \n",
    "    return author_zscores.loc[author_zscores > threshold]\n",
    "\n",
    "\n",
    "\n",
    "get_author_identifying_features(\"en_113\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5895ca8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/wordclouds/en_76_wc.png\n",
      "data/wordclouds/en_19_wc.png\n",
      "data/wordclouds/en_52_wc.png\n",
      "data/wordclouds/en_97_wc.png\n",
      "data/wordclouds/en_112_wc.png\n",
      "data/wordclouds/en_100_wc.png\n",
      "data/wordclouds/en_99_wc.png\n",
      "data/wordclouds/en_102_wc.png\n",
      "data/wordclouds/en_110_wc.png\n",
      "data/wordclouds/en_78_wc.png\n",
      "data/wordclouds/en_2_wc.png\n",
      "data/wordclouds/en_66_wc.png\n",
      "data/wordclouds/en_74_wc.png\n",
      "data/wordclouds/en_21_wc.png\n",
      "data/wordclouds/en_114_wc.png\n",
      "data/wordclouds/en_37_wc.png\n",
      "data/wordclouds/en_54_wc.png\n",
      "data/wordclouds/en_58_wc.png\n",
      "data/wordclouds/en_13_wc.png\n",
      "data/wordclouds/en_62_wc.png\n",
      "data/wordclouds/en_56_wc.png\n",
      "data/wordclouds/en_35_wc.png\n",
      "data/wordclouds/en_60_wc.png\n",
      "data/wordclouds/en_4_wc.png\n",
      "data/wordclouds/en_72_wc.png\n",
      "data/wordclouds/en_11_wc.png\n",
      "data/wordclouds/en_104_wc.png\n",
      "data/wordclouds/en_108_wc.png\n",
      "data/wordclouds/en_113_wc.png\n",
      "data/wordclouds/en_101_wc.png\n",
      "data/wordclouds/en_96_wc.png\n",
      "data/wordclouds/en_53_wc.png\n",
      "data/wordclouds/en_22_wc.png\n",
      "data/wordclouds/en_77_wc.png\n",
      "data/wordclouds/en_18_wc.png\n",
      "data/wordclouds/en_20_wc.png\n",
      "data/wordclouds/en_51_wc.png\n",
      "data/wordclouds/en_67_wc.png\n",
      "data/wordclouds/en_3_wc.png\n",
      "data/wordclouds/en_75_wc.png\n",
      "data/wordclouds/en_103_wc.png\n",
      "data/wordclouds/en_111_wc.png\n",
      "data/wordclouds/en_98_wc.png\n",
      "data/wordclouds/en_12_wc.png\n",
      "data/wordclouds/en_63_wc.png\n",
      "data/wordclouds/en_55_wc.png\n",
      "data/wordclouds/en_36_wc.png\n",
      "data/wordclouds/en_59_wc.png\n",
      "data/wordclouds/en_107_wc.png\n",
      "data/wordclouds/en_105_wc.png\n",
      "data/wordclouds/en_109_wc.png\n",
      "data/wordclouds/en_5_wc.png\n",
      "data/wordclouds/en_61_wc.png\n",
      "data/wordclouds/en_73_wc.png\n",
      "data/wordclouds/en_34_wc.png\n",
      "data/wordclouds/en_57_wc.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file in Path(\"data/wordclouds/\").glob(\"*\"):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa87e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en_35'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_df.iloc[0].author_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18336b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb4199edec22ad1db1c68636577eb450b142028077a33030af62183bdb2afb02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
